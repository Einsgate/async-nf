\section{Introduction}

% nfv潮流试图将硬件middlebox替换为运行在虚拟环境中的软件middlebox，从而使关键话网络服务的部署和供给变得简单。由于软件middlebox需要被部署在关键的网络节点上，比如lte网络的骨干网络上，软件middlebox必须具有极高的性能。

The trend of Network Function Virtualization (NFV) \cite{nfv-website} aims to replace hardware middleboxes with software middleboxes running in virtualized environment. NFV greatly facilitates the deployment and provisioning of key network services. Since software middleboxes must be placed on critical network paths, such as backbone of LTE network \cite{201569}, the performance of software middleboxes must be good enough to process packets at 10/40Gbps line rate.

Besides being high performance, the ability to handle asynchronous operations is also very important to NFV. First, some middlboxes need to collaborate with each other by passing requests and responses. For instance, the middleboxes on the control plane of IMS system \cite{3gpp-ims} exchange a large number of SIP \cite{sip} requests and responses to establish a IP voice call. Second, middleboxes sometimes need to contact external service while processing flows. Stateless network function \cite{201545} stores critical flow states on an external key-value store \cite{ousterhout2015ramcloud}, for scalability and resilience. Middlebox that handle application-level protocols, like the middleboxes on the control plane of IMS system \cite{}, need to query a DNS server to identify the next-hop middlebox instance to contact with. To achieve good performance, all these middleboxes that are mentioned are preferably to handle asynchronous operations in a fully non-blocking manner.

% 为了提高软件middlebox的性能，主流的做法是跨越整个内核，并让软件middlebox直接在用户空间利用高效包处理库进行包处理。这种架构通常提供若干个工作线程直接对网卡进行繁忙轮训，以避免发送和接受包时由于内核用户空间的上下文切换而造成的巨大overhead，而这种overhead会对每秒钟需要处理几百万个包的软件middlebox产生极大的性能影响。

However, when implementing middleboxes with the state-of-art technique, non-blocking asynchronous operations can not be gracefully handled in a way that is both efficient and manageable. Today, most high-performance middleboxes bypass the kernel networking stack and process packets completely in user space with user space packet I/O frameworks, such as DPDK \cite{} and Netmap \cite{}. The user space packet I/O frameworks assign several worker threads to busily poll the network interface card (NIC) for packets, so that the overhead caused by context switches when calling traditional kernel I/O system calls is completely avoided. The use of a busy poll loop makes user-spacke packet I/O framework both efficient and easy to program with. But when incorporating asynchronous operations into the user-space packet I/O framework, a dilemma is encountered. If one would like the middlebox implementation to be easily manageable, he can replace asynchronous operations with synchronous blocking operations, but that will seriously damange the runtime performance of middleboxes, as high-performance middleboxes can not even tolerate the overhead brought by context switches. If one would like the middlebox implementation to be highly efficient, he can achieve the goal with a combination of mutable state and callback functions, but this makes middlebox implementation hard to manage, as a middlebox implementation may require to query a key-value store several times in order to process a single packet \cite{}.

%However, the use of user space I/O frameworks also limit the dominant working modes of software middleboxes to the following two, which are run-to-completion mode and pipelining mode. Run-to-completion \cite{} mode handles the fetching, processing and releasing of packets all within a single poll loop. Pipelining mode \cite{} distributes the packet processing job to multiple worker threads, each runs its own poll loop: when the poll loop of a worker thread finishes processing a packet, it hands the packet over to the next worker thread on the pipeline, or releases the packet to the outside if it is the last worker thread on the pipeline.

% 但是，这种基于用户层高性能网络报io的架构也限制了软件middlebox的工作模式，分别是run-to-completion模式和pipelining mode。run-to-completion mode在一个poll loop中完成从抓包，处理包，到把包释放出的全部过程。pipelineing mode则把包处理工作分配到多个工作线程中，当一个工作线程的poll loop完成自己的任务后，它会将包交给下一个工作线程，直到这个包被pipeline上的最后一个工作线程释放出去。这两种工作方式十分高效，并且容易编程实现。但是，这两种工作方式通常只能使用同步的方式来响应异步事件，例如进行dns查询并等待它的返回结果。这种同步的方式会极大的影响middlebox的性能。



%Both of the two working modes are highly efficient and easy to program with. However, it's hard for these two working modes to handle non-blocking asynchronous operations, i.e. perform a DNS query and wait for the response. It is trivial to integrate a blocking synchronous operation into the poll loop, but blocking synchronous operations are not efficient and will seriously damage the runtime performance of software middleboxes. It is possible to use callbacks to perform asynchronous operations, but this makes the middlebox code hard to manage, as compared to synchronous operations.



% 现有的nfv系统中也有很多响应异步事件的，例如mOS。mOS将poll loop进行了分装，并抽象出包处理过程中的事件，这些事件会被用户注册的回调函数进行响应，从而实现异步的事件处理。但是，当程序员使用mOS时，他需要使用回调函数来串接处理逻辑。和传统的工作模式相比，这种方法会打乱程序的控制流，从而使得程序员更难reason about程序。同时，mOS所暴露出的事件使基于包到达以及tcp状态机的改变的事件，这些事件并不general，无法捕捉更多工作，例如查询外部的存储设备。

There are several existing frameworks that aim to provide asynchronous event processing for middleboxes, including mOS \cite{}, libnids \cite{} and etc. These frameworks expose TCP related flow events to the middlebox programmer and enable these events to be processed in a non-blocking asynchronous manner. However, these frameworks are still based on callback-based design, making the code harder to manage when handling complex middlebox logic. They only concentrate on handling flow-level events that are related to TCP/IP protocol and they are not general enough to handle other asynchronous operations like database query.

% 在这篇论文中，我们呈现NetStar，一个为middlebox的编写提供highly scalable, lightweight异步事件处理的编程平台。NetStar基于开源事件驱动框架Seastar进行构建并使用了先进的promise-continuation编程模型。与之前的系统比较，NetStar使得middlebox可以灵活的，无阻塞的响应各种异步事件，同时也使的异步的middlebox更容易去reason，更容易实现。我们必须承认的是，为了实现高效异步事件处理，NetStar确实使用了一些抽象，但是这些抽象只会带来moderate overhead，而且NetStar仍然具有极强的多核扩展能力。

In this paper, we present NetStar, a framework for implementing middleboxes that perform non-blocking asynchronous operations. NetStar is built upon open-source asynchronous library Seastar \cite{} and provides basic constructs for building middleboxes. When compared with previous frameworks, NetStar exhibit the following advantages.

\textbf{NetStar handles asynchronous operations of middleboxes in a way that is both efficient and manageable.} Asynchronous operations in NetStar are accomplished through through callbacks, making NetStar highly efficient. However, the callbacks in NetStar are used in an implicit way that mimics the style of synchronous operations, making them easy to program with and reason about. NetStar's power comes from the promise-continuation programming model provided by Seastar \cite{} and advanced C++ features, such as lambda expression \cite{}.

\textbf{NetStar has good multi-core scalability and performance.} NetStar achieves multi-core scalability with hardware assistance. The input network traffic are automatically distributed to each core by NIC using RSS \cite{}, so that so that different cores can operate in a fully parallel fashion without contending for shared resources. NetStar is programmed with C++14 using various zero-cost abstractions. Even though the promise-continuation model that NetStar uses to implement asynchronous operations do pose slight runtime overhead, NetStar is able to compensate the overhead with multi-core scalability and achieve line-rate processing.

Using NetStar, it would be easy to implement traditional asynchronous operations such as DNS querying. Instead, we use NetStar to solve some important research problems that are raised recently.

\textbf{First,} we use NetStar to implement a non-blocking version of stateless network function \cite{}. Stateless network function \cite{} has demonstrated great potential for dynamic scaling and resilience. However, its current implementation is blocking and synchronous, making its maximum performance inferior when compared to other state-of-art middlebox systems \cite{}. We use NetStar to transform stateless network function into a non-blocking and asynchronous one and pairs it with a key-value store \cite{} with better performance than RamCloud \cite{}. Besides significantly improving the performance of stateless network function, we further identify a race problem when accessing the shared state stored on a key-value store by stateless network function. Without using NetStar, it would be hard to solve such a problem.



% 利用NetStar，我们可以很轻松的实现异步DNS查询等传统功能。为了展现NetStar的真正能力，我们着重解决最近研究界提出的几个问题：

% 实现异步无阻塞的Stateless Network Function: Stateless Network Function架构对于网络功能的容错和动态扩展都有重要价值。但是，现有的Stateless Network Function是基于一个完全同步的架构，工作线程需要对异步操作进行阻塞性等待。这使得Stateless Network Function无法有效的利用CPU资源。我们利用NetStar对Stateless Network Function进行了重写，将所有的同步等待转换成异步操作，从而极大的提高了Stateless Network Function的运行效率，同时保持了Stateless NF代码逻辑的可读性。我们也发现了Stateless Network Function在处理共享状态时的一个问题，并利用NetStar框架对其进行了有效的解决。

% 共享数据结构的访问：为了序列化共享数据结构的访问，传统NF需要对共享数据结构进行加锁。我们则利用NetSeatar框架，将访问共享数据结构的过程做成了一个消息传递过程：共享数据结构被做成了一个服务，所有工作线程对它的访问都被转换成了发送消息并接收消息访问结果。这样做保证了共享数据结构访问的线性化，同时，我们在实验中展示这样做的性能损耗并不比利用锁来处理多多少。但是这样做可以带来两个好处，首先，这样做可以解决上述提到的Stateless Network Function在处理共享状态时的多线程race问题，第二，我们可以有效记录共享数据结构的访问顺序，并有效的按照锁记录的访问顺序复制对共享数据的访问。这使得我们可以构建一个主机从机完全一致的主从复制系统，我们在实验中展示了这个系统的性能。

\textbf{Second,} we use NetStar to serialize access to shared data structures of middleboxes. Traditional middleboxes need to use lock to serialize the access to a shared data structures from multiple worker threads. We treat shared data structures as a dedicated service and convert the regular access-after-lock pattern to send-query-wait-response pattern. The new pattern is reasonably fast when compared to the access-after-lock pattern. It provides two additional benefits. First, it helps us solve the shared state access problem of stateless network function mentioned above. Second, it enables the middlebox to record the access order of any shared variables, so that another middlebox can replay the recorded access order in a deterministic fashion. We use this feature to build a primary-backup replication system for middleboxes. It's primary and back instances are always in synchronization and it has zero recovery time after primary failure.

% 作为一个探索异步操作在middlebox中实现的平台，NetStar并没有去port很多已有的middlebox。坦白来讲，由于NetStar使用了新的编程抽象，并且大量使用了C++14的语法特性，将已有的middlebox port到NetStar需要一定additional的工作量。但是，本文的重点是为了展示NetStar对支持middlebox异步操作的有效性，我们所制作的全异步Stateless Network Function相比同步的版本有重大的性能提升。其次，我们相信NetStar有足够的能力去支持更多的middlebox，NetStar基于的SeaStar平台带有内建的TCP/IP stack，这让我们有充足的理由去相信，NetStar可以支持支持mOS，因为mOS基于mTCP。

Due to the use of new programming model and massive use of C++14 feature, porting existing middleboxes to NetStar may require non-trivial amount of work. However, as a new framework for exploring how asynchronous operations can be implemented in middleboxes, porting existing middleboxes is not our primary goal. We also believe that the constructs provided by NetStar for building middleboxes are general enough to implement other middleboxes that do not perform asynchronous operations.

The paper is organized as follows. We introduce our primary motivation in section 2. The overall architecture of NetStar is given in section 3. We discuss the design of asynchronous stateless network function and serialized shared data structure access in section 4. The performance of asynchronous stateless network function and a NAT is discussed in section 5. We discuss related work in section 6 and conclude the paper in section 7.

%这篇文章的组织如下。我们在第二章介绍我们的主要motivation。在第三张，我们对NetStar框架进行一个详细介绍。在第四章，我们详细介绍异步stateless middlebox和共享数据结构的访问。我们在第五章呈现我们的evaluation结果。在第六章讨论related work。并在第七章给出论文的结论。
